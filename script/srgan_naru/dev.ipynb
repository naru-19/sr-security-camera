{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode as IMode\n",
    "from torch.utils.data import DataLoader\n",
    "from narutils import *\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from utils.imgproc import *\n",
    "from model import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうやらSRGANは最初のp_epochsはgeneratorだけを学習，advはepochsだけらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file paths\n",
    "data_dir='/work/dataset/images1024x1024/'\n",
    "fpaths=[]\n",
    "for d in os.listdir(data_dir):\n",
    "\tfpaths+=glob(opj(data_dir,d,'*.png'))\n",
    "path_df=dfc(fpaths).rename(columns={0:'file_path'}).to_csv('path_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "\tdevice = torch.device(\"cuda:0\")\n",
    "\tseed=19\n",
    "\tupscale_factor=4\n",
    "\timage_size=512 # hr image size(low res image size=image_size/upscale_factor)\n",
    "\tbatch_size=4\n",
    "\n",
    "\t# Train epochs.\n",
    "\tp_epochs=2 # The total number of cycles of the generator training phase.\n",
    "\tepochs=10  # The total number of cycles in the training phase of the adversarial network.\n",
    "\n",
    "\n",
    "\texp_name='test'\n",
    "\tmodel_dir=opj('output',exp_name)\n",
    "\toutput_dir=opj('output',exp_name)\n",
    "\n",
    "\tvgg_path='/work/dataset/vgg-pre.pickle'\n",
    "\ttrain_path_df=pd.read_csv('path_df.csv').iloc[:5000,:]\n",
    "\tvalid_path_df=pd.read_csv('path_df.csv').iloc[5000:10000,:]\n",
    "\n",
    "\tpixel_weight          = 0.01\n",
    "\tcontent_weight        = 1.0\n",
    "\tadversarial_weight    = 0.001\n",
    "\n",
    "\tdebug=True\n",
    "\t# debug=False\n",
    "\n",
    "\n",
    "\tif debug:\n",
    "\t\ttrain_path_df=train_path_df.iloc[:8,:]\n",
    "\t\tvalid_path_df=valid_path_df.iloc[:8,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self,cfg,mode='train'):\n",
    "\t\tlr_image_size=(cfg.image_size//cfg.upscale_factor,cfg.image_size//cfg.upscale_factor)\n",
    "\t\thr_image_size=(cfg.image_size,cfg.image_size)\n",
    "\t\tself.hr_transforms=transforms.Compose([\n",
    "\t\t\ttransforms.Resize(hr_image_size,interpolation=IMode.BICUBIC),\n",
    "\t\t])\n",
    "\t\tself.lr_transforms=transforms.Compose([\n",
    "\t\t\ttransforms.Resize(lr_image_size,interpolation=IMode.BICUBIC),\n",
    "\t\t])\n",
    "\t\tif mode=='train':\n",
    "\t\t\tself.filenames=cfg.train_path_df['file_path'].values\n",
    "\t\telif mode=='valid':\n",
    "\t\t\tself.filenames=cfg.valid_path_df['file_path'].values\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError\n",
    "\n",
    "\tdef __getitem__(self,index):\n",
    "\t\thr=image2tensor(cv2.imread(self.filenames[index],-1))\n",
    "\t\tlr=self.lr_transforms(hr)\n",
    "\t\thr=self.hr_transforms(hr)\n",
    "\t\treturn lr,hr\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN():\n",
    "\tdef __init__(self,cfg):\n",
    "\t\tself.cfg=cfg\n",
    "\n",
    "\tdef build_dataloader(self,CustomDataset):\n",
    "\t\tself.train_dataset=CustomDataset(self.cfg,mode='train')\n",
    "\t\tself.valid_dataset=CustomDataset(self.cfg,mode='valid')\n",
    "\n",
    "\t\tself.train_loader=DataLoader(self.train_dataset,self.cfg.batch_size,True,pin_memory=True)\n",
    "\t\tself.valid_loader=DataLoader(self.valid_dataset,self.cfg.batch_size,True,pin_memory=True)\n",
    "\n",
    "\t\tdecopri('successfully built data loaders!')\n",
    "\n",
    "\tdef build_model(self):\n",
    "\t\tself.discriminator=Discriminator().to(self.cfg.device)\n",
    "\t\tself.generator=Generator().to(self.cfg.device)\n",
    "\n",
    "\t\tdecopri('successfully built models!')\n",
    "\n",
    "\tdef train_generator(self,epoch):\n",
    "\t\t\"\"\"Only train the generative model.\n",
    "\t\tArgs:\n",
    "\t\t\ttrain_dataloader (torch.utils.data.DataLoader): The loader of the training data set.\n",
    "\t\t\tepoch (int): number of training cycles.\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t# Calculate how many iterations there are under Epoch.\n",
    "\t\tbatches = len(self.train_loader)\n",
    "\t\t# Put the generative model in training mode.\n",
    "\t\tself.generator.train()\n",
    "\t\tpbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader), desc=f'Train generator|epoch{epoch}',dynamic_ncols=True)\n",
    "\t\tfor index, (lr, hr) in pbar:\n",
    "\t\t\t# Copy the data to the specified device.\n",
    "\t\t\tlr = lr.to(cfg.device)\n",
    "\t\t\thr = hr.to(cfg.device)\n",
    "\t\t\t# Initialize the gradient of the generated model.\n",
    "\t\t\tself.generator.zero_grad()\n",
    "\t\t\t# Generate super-resolution images.\n",
    "\t\t\tsr = self.generator(lr)\n",
    "\t\t\t# Calculate the difference between the super-resolution image and the high-resolution image at the pixel level.\n",
    "\t\t\tpixel_loss = self.pixel_criterion(sr, hr)\n",
    "\t\t\t# Update the weights of the generated model.\n",
    "\t\t\tpixel_loss.backward()\n",
    "\t\t\tself.p_optimizer.step()\n",
    "\n",
    "\n",
    "\t\n",
    "\tdef train_adversarial(self, epoch) :\n",
    "\t\t\"\"\"Training generative models and adversarial models.\n",
    "\t\t\"\"\"\n",
    "\t\t# Calculate how many iterations there are under Epoch.\n",
    "\t\tbatches = len(self.train_loader)\n",
    "\t\t# Put the two models in training mode.\n",
    "\t\tself.discriminator.train()\n",
    "\t\tself.generator.train()\n",
    "\t\tpbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader), desc=f'Train generator|epoch{epoch}',dynamic_ncols=True)\n",
    "\t\tfor index, (lr, hr) in pbar:\n",
    "\t\t\t# Copy the data to the specified device.\n",
    "\t\t\tlr = lr.to(self.cfg.device)\n",
    "\t\t\thr = hr.to(self.cfg.device)\n",
    "\t\t\tlabel_size = lr.size(0)\n",
    "\t\t\t# 打label. Set the real sample label to 1, and the false sample label to 0.\n",
    "\t\t\treal_label = torch.full([label_size, 1], 1.0, dtype=lr.dtype, device=self.cfg.device)\n",
    "\t\t\tfake_label = torch.full([label_size, 1], 0.0, dtype=lr.dtype, device=self.cfg.device)\n",
    "\n",
    "\t\t\t# Initialize the identification model gradient.\n",
    "\t\t\tself.discriminator.zero_grad()\n",
    "\t\t\t# Generate super-resolution images.\n",
    "\t\t\tsr = self.generator(lr)\n",
    "\t\t\t# Calculate the loss of the identification model on the high-resolution image.\n",
    "\t\t\thr_output = self.discriminator(hr)\n",
    "\n",
    "\t\t\tsr_output = self.discriminator(sr.detach())\n",
    "\t\t\tdiff=hr_output - torch.mean(sr_output)\n",
    "\t\t\tdiff[diff<0]=0\n",
    "\t\t\td_loss_hr = self.adversarial_criterion(diff, real_label)\n",
    "\t\t\td_loss_hr.backward()\n",
    "\t\t\td_hr = hr_output.mean().item()\n",
    "\t\t\t# Calculate the loss of the identification model on the super-resolution image.\n",
    "\t\t\thr_output = self.discriminator(hr)\n",
    "\n",
    "\t\t\tsr_output = self.discriminator(sr.detach())\n",
    "\t\t\tdiff=sr_output - torch.mean(hr_output)\n",
    "\t\t\tdiff[diff<0]=0\n",
    "\t\t\td_loss_sr = self.adversarial_criterion(diff, fake_label)\n",
    "\t\t\td_loss_sr.backward()\n",
    "\t\t\td_sr1 = sr_output.mean().item()\n",
    "\t\t\t# Update the weights of the authentication model.\n",
    "\t\t\td_loss = d_loss_hr + d_loss_sr\n",
    "\t\t\tself.d_optimizer.step()\n",
    "\n",
    "\t\t\t# Initialize the gradient of the generated model.\n",
    "\t\t\tself.generator.zero_grad()\n",
    "\t\t\t# Generate super-resolution images.\n",
    "\t\t\tsr = self.generator(lr)\n",
    "\t\t\t# Calculate the loss of the identification model on the super-resolution image.\n",
    "\t\t\thr_output = self.discriminator(hr.detach())\n",
    "\t\t\tsr_output = self.discriminator(sr)\n",
    "\t\t\t# Perceptual loss = 0.01 * pixel loss + 1.0 * content loss + 0.005 * counter loss.\n",
    "\t\t\tpixel_loss = self.cfg.pixel_weight * self.pixel_criterion(sr, hr.detach())\n",
    "\t\t\tcontent_loss = self.cfg.content_weight * self.content_criterion(sr, hr.detach())\n",
    "\t\t\tdiff=sr_output - torch.mean(hr_output)\n",
    "\t\t\tdiff[diff<0]=0\n",
    "\t\t\tadversarial_loss = self.cfg.adversarial_weight * self.adversarial_criterion(diff, real_label)\n",
    "\t\t\t# Update the weights of the generated model.\n",
    "\t\t\tg_loss = pixel_loss + content_loss + adversarial_loss\n",
    "\t\t\tg_loss.backward()\n",
    "\t\t\tself.g_optimizer.step()\n",
    "\t\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tself.p_optimizer=optim.Adam(self.generator.parameters(),0.0001,(0.9, 0.999))  # Generate model learning rate during generator training.\n",
    "\t\tself.d_optimizer=optim.Adam(self.discriminator.parameters(),0.0001,(0.9, 0.999))  # Discriminator learning rate during adversarial network training.\n",
    "\t\tself.g_optimizer=optim.Adam(self.generator.parameters(),0.0001,(0.9, 0.999))  # The learning rate of the generator during network training.\n",
    "\n",
    "\t\t# Scheduler.\n",
    "\t\tself.d_scheduler=StepLR(self.d_optimizer, self.cfg.epochs // 2, 0.1)  # Identify the model scheduler during adversarial training.\n",
    "\t\tself.g_scheduler=StepLR(self.g_optimizer, self.cfg.epochs // 2, 0.1)\n",
    "\t\t\n",
    "\t\t# Loss functions\n",
    "\t\tself.pixel_criterion=nn.MSELoss().to(cfg.device)               # Pixel loss.\n",
    "\t\tself.content_criterion=ContentLoss(cfg).to(cfg.device)              # Content loss.\n",
    "\t\tself.adversarial_criterion=nn.BCELoss().to(cfg.device) \n",
    "\n",
    "\t\t# train only generator stage\n",
    "\t\tdecopri('Start train generator stage')\n",
    "\t\tpsnr_best=0.0\n",
    "\t\tfor epoch in range(self.cfg.p_epochs):\n",
    "\t\t\tself.train_generator(epoch)\n",
    "\t\t\tpsnr=self.validate(epoch,stage='generator only')\n",
    "\t\t\tif (epoch+1)%5==0:\n",
    "\t\t\t\ttorch.save(self.generator.state_dict(),opj(self.cfg.model_dir,f'p-{epoch}.pth'))\n",
    "\t\t\tif psnr>psnr_best:\n",
    "\t\t\t\tpsnr_best=psnr\n",
    "\t\t\t\tmkdirs(self.cfg.model_dir)\n",
    "\t\t\t\ttorch.save(self.generator.state_dict(),opj(self.cfg.model_dir,'p-best.pth'))\n",
    "\t\t\t\tprint(f'generator saved {opj(self.cfg.model_dir,\"p-best.pth\")}')\n",
    "\t\t\n",
    "\t\t# train adversarial stage\n",
    "\t\tdecopri('Start train adversarial stage')\n",
    "\t\tself.generator.load_state_dict(torch.load(opj(cfg.model_dir,'p-best.pth')))\n",
    "\t\tfor epoch in range(self.cfg.epochs):\n",
    "\t\t\tself.train_adversarial(epoch)\n",
    "\t\t\tpsnr=self.validate(epoch,stage='adversarial')\n",
    "\t\t\tif (epoch+1)%5==0:\n",
    "\t\t\t\ttorch.save(self.generator.state_dict(),opj(self.cfg.model_dir,f'g-{epoch}.pth'))\n",
    "\t\t\t\ttorch.save(self.discriminator.state_dict(),opj(self.cfg.model_dir,f'd-{epoch}.pth'))\n",
    "\t\t\tif psnr>psnr_best:\n",
    "\t\t\t\tpsnr_best=psnr\n",
    "\t\t\t\ttorch.save(self.generator.state_dict(),opj(self.cfg.model_dir,'g-best.pth'))\n",
    "\t\t\t\ttorch.save(self.discriminator.state_dict(),opj(self.cfg.model_dir,'d-best.pth'))\n",
    "\n",
    "\t\t\tself.d_scheduler.step()\n",
    "\t\t\tself.g_scheduler.step()\n",
    "\n",
    "\tdef validate(self,epoch,stage='adversarial'):\n",
    "\t\tbatches=len(self.valid_loader)\n",
    "\t\tself.generator.eval()\n",
    "\t\ttotal_psnr_value=0.0\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tpbar=tqdm(enumerate(self.valid_loader), total=len(self.valid_loader), desc=f'valid {stage}|epoch{epoch}',dynamic_ncols=True)\n",
    "\t\t\tfor index,(lr,hr) in pbar:\n",
    "\t\t\t\tlr = lr.to(self.cfg.device)\n",
    "\t\t\t\thr = hr.to(self.cfg.device)\n",
    "\n",
    "\t\t\t\t# Generate super-resolution images.\n",
    "\t\t\t\tsr = self.generator(lr)\n",
    "\t\t\t\tif index==0 and (epoch+1)%5==0:\n",
    "\t\t\t\t\tsave_filename=['lr','hr','sr']\n",
    "\t\t\t\t\tprint(sr)\n",
    "\t\t\t\t\tfor i,save_img in enumerate([lr,hr,sr]):\n",
    "\t\t\t\t\t\timg=(save_img[0].permute(1,2,0).to('cpu').detach().numpy().copy()*255).astype(int)\n",
    "\t\t\t\t\t\tmkdirs(self.cfg.output_dir)\n",
    "\t\t\t\t\t\tcv2.imwrite(opj(self.cfg.output_dir,f'epoch{epoch}-{save_filename[i]}.png'),img)\n",
    "\n",
    "\t\t\t\t# Calculate the PSNR indicator.\n",
    "\t\t\t\tmse_loss = ((sr - hr) ** 2).data.mean()\n",
    "\t\t\t\tpsnr_value = 10 * torch.log10(1 / mse_loss).item()\n",
    "\t\t\t\ttotal_psnr_value += psnr_value\n",
    "\t\t\t\n",
    "\t\t\tavg_psnr_value=total_psnr_value/batches\n",
    "\t\t\tprint(f'epoch-{epoch} average psnr:{avg_psnr_value}')\n",
    "\n",
    "\t\treturn avg_psnr_value\n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "                        successfully built data loaders!                        \n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "                           successfully built models!                           \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "srgan=SRGAN(cfg)\n",
    "srgan.build_dataloader(CustomDataset=CustomDataset)\n",
    "srgan.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "                          Start train generator stage                          \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch0: 100%|██████████| 2/2 [00:05<00:00,  2.66s/it]\n",
      "valid generator only|epoch0: 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0 average psnr:5.765288472175598\n",
      "generator saved ././output/test/p-best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch1: 100%|██████████| 2/2 [00:01<00:00,  1.85it/s]\n",
      "valid generator only|epoch1: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-1 average psnr:5.886972993612289\n",
      "generator saved ././output/test/p-best.pth\n",
      "--------------------------------------------------------------------------------\n",
      "                         Start train adversarial stage                         \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch0: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]\n",
      "valid adversarial|epoch0: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0 average psnr:5.813097357749939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch1: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "valid adversarial|epoch1: 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-1 average psnr:5.9243229031562805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch2: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n",
      "valid adversarial|epoch2: 100%|██████████| 2/2 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-2 average psnr:5.904753804206848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch3: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "valid adversarial|epoch3: 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-3 average psnr:5.848830044269562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch4: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n",
      "valid adversarial|epoch4:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.0928e-03,  1.5075e-03,  1.1257e-03,  ...,  1.7241e-03,\n",
      "            1.0826e-03,  1.3316e-03],\n",
      "          [ 1.4824e-03,  1.4855e-03,  1.8642e-03,  ...,  1.6695e-03,\n",
      "            1.7536e-03,  1.3830e-03],\n",
      "          [ 1.1599e-03,  1.9522e-03,  1.3443e-03,  ...,  2.2955e-03,\n",
      "            1.3074e-03,  1.7431e-03],\n",
      "          ...,\n",
      "          [ 1.8530e-03,  1.7338e-03,  2.4451e-03,  ...,  2.6498e-03,\n",
      "            2.4878e-03,  2.1399e-03],\n",
      "          [ 1.2167e-03,  1.9303e-03,  1.3655e-03,  ...,  2.7864e-03,\n",
      "            1.5918e-03,  2.1521e-03],\n",
      "          [ 1.5208e-03,  1.4697e-03,  1.9246e-03,  ...,  2.0201e-03,\n",
      "            2.0231e-03,  1.6731e-03]],\n",
      "\n",
      "         [[ 1.7079e-03,  2.4605e-03,  1.9241e-03,  ...,  2.9415e-03,\n",
      "            1.8967e-03,  2.3596e-03],\n",
      "          [ 2.4326e-03,  2.4080e-03,  3.1146e-03,  ...,  3.1097e-03,\n",
      "            2.9457e-03,  2.5015e-03],\n",
      "          [ 1.9595e-03,  3.0722e-03,  2.2974e-03,  ...,  3.9276e-03,\n",
      "            2.4005e-03,  2.9949e-03],\n",
      "          ...,\n",
      "          [ 2.9579e-03,  2.9351e-03,  3.8627e-03,  ...,  4.5774e-03,\n",
      "            4.4873e-03,  3.5052e-03],\n",
      "          [ 2.1154e-03,  2.9366e-03,  2.4966e-03,  ...,  4.6655e-03,\n",
      "            2.8958e-03,  3.6000e-03],\n",
      "          [ 2.3786e-03,  2.2828e-03,  3.0762e-03,  ...,  3.3531e-03,\n",
      "            3.4541e-03,  2.8304e-03]],\n",
      "\n",
      "         [[-2.2817e-04,  3.5721e-04,  5.4009e-05,  ...,  7.3427e-04,\n",
      "           -1.2690e-05,  3.9010e-04],\n",
      "          [ 3.8948e-04,  2.2793e-04,  8.4335e-04,  ...,  5.3202e-04,\n",
      "            9.3293e-04,  1.0443e-04],\n",
      "          [-3.0865e-05,  8.2231e-04,  3.2245e-04,  ...,  1.4854e-03,\n",
      "            3.3365e-04,  7.4932e-04],\n",
      "          ...,\n",
      "          [ 8.8599e-04,  5.6508e-04,  1.7456e-03,  ...,  1.2950e-03,\n",
      "            2.1106e-03,  7.1047e-04],\n",
      "          [-1.5063e-04,  7.3843e-04,  2.3876e-04,  ...,  1.8610e-03,\n",
      "            6.9089e-04,  9.4032e-04],\n",
      "          [ 3.8502e-04,  8.1787e-05,  9.8291e-04,  ...,  8.4926e-04,\n",
      "            1.2667e-03,  3.5290e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0364e-03,  1.3584e-03,  1.0651e-03,  ...,  1.3852e-03,\n",
      "            9.8172e-04,  1.1429e-03],\n",
      "          [ 1.3448e-03,  1.3292e-03,  1.6002e-03,  ...,  1.3510e-03,\n",
      "            1.3847e-03,  1.1785e-03],\n",
      "          [ 1.0855e-03,  1.6727e-03,  1.1991e-03,  ...,  1.6687e-03,\n",
      "            1.0962e-03,  1.3642e-03],\n",
      "          ...,\n",
      "          [ 1.3770e-03,  1.3246e-03,  1.6398e-03,  ...,  1.6091e-03,\n",
      "            1.5515e-03,  1.4029e-03],\n",
      "          [ 1.0321e-03,  1.4054e-03,  1.0938e-03,  ...,  1.6673e-03,\n",
      "            1.1301e-03,  1.4051e-03],\n",
      "          [ 1.2341e-03,  1.1864e-03,  1.4010e-03,  ...,  1.3804e-03,\n",
      "            1.3749e-03,  1.2293e-03]],\n",
      "\n",
      "         [[ 1.6223e-03,  2.2090e-03,  1.7676e-03,  ...,  2.2455e-03,\n",
      "            1.6732e-03,  1.9451e-03],\n",
      "          [ 2.1947e-03,  2.1962e-03,  2.6768e-03,  ...,  2.3553e-03,\n",
      "            2.2946e-03,  2.0201e-03],\n",
      "          [ 1.8035e-03,  2.6350e-03,  2.0481e-03,  ...,  2.7819e-03,\n",
      "            1.9191e-03,  2.2981e-03],\n",
      "          ...,\n",
      "          [ 2.2034e-03,  2.2068e-03,  2.6322e-03,  ...,  2.6676e-03,\n",
      "            2.6558e-03,  2.2901e-03],\n",
      "          [ 1.7372e-03,  2.2073e-03,  1.9240e-03,  ...,  2.7460e-03,\n",
      "            1.9809e-03,  2.3481e-03],\n",
      "          [ 1.9322e-03,  1.8825e-03,  2.2463e-03,  ...,  2.2458e-03,\n",
      "            2.2615e-03,  2.0238e-03]],\n",
      "\n",
      "         [[-2.9572e-04,  1.4931e-04, -9.8462e-05,  ...,  1.9161e-04,\n",
      "           -2.4062e-04, -1.2121e-05],\n",
      "          [ 1.6950e-04,  4.1115e-05,  5.1417e-04,  ...,  3.6841e-05,\n",
      "            2.8981e-04, -1.8340e-04],\n",
      "          [-1.6977e-04,  4.9020e-04,  9.5447e-05,  ...,  5.6988e-04,\n",
      "           -6.3052e-05,  1.9122e-04],\n",
      "          ...,\n",
      "          [ 2.0857e-04, -1.9360e-05,  6.0089e-04,  ...,  1.9800e-04,\n",
      "            5.6029e-04, -2.1939e-05],\n",
      "          [-3.6130e-04,  1.1035e-04, -1.3848e-04,  ...,  4.0986e-04,\n",
      "           -4.6634e-05,  6.8347e-05],\n",
      "          [-3.8190e-05, -2.3175e-04,  2.5124e-04,  ..., -6.3977e-06,\n",
      "            2.5017e-04, -1.7367e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0766e-03,  1.4810e-03,  1.1114e-03,  ...,  1.1970e-03,\n",
      "            9.3739e-04,  1.0608e-03],\n",
      "          [ 1.4557e-03,  1.4149e-03,  1.8035e-03,  ...,  1.1871e-03,\n",
      "            1.2109e-03,  1.0857e-03],\n",
      "          [ 1.1565e-03,  1.8956e-03,  1.2835e-03,  ...,  1.3680e-03,\n",
      "            9.8559e-04,  1.1803e-03],\n",
      "          ...,\n",
      "          [ 1.8361e-03,  1.7186e-03,  2.4193e-03,  ...,  1.8453e-03,\n",
      "            1.7734e-03,  1.5663e-03],\n",
      "          [ 1.2169e-03,  1.9067e-03,  1.3361e-03,  ...,  1.9256e-03,\n",
      "            1.2416e-03,  1.5841e-03],\n",
      "          [ 1.5154e-03,  1.4814e-03,  1.9117e-03,  ...,  1.5316e-03,\n",
      "            1.5235e-03,  1.3306e-03]],\n",
      "\n",
      "         [[ 1.6785e-03,  2.4068e-03,  1.8992e-03,  ...,  1.9275e-03,\n",
      "            1.5713e-03,  1.7487e-03],\n",
      "          [ 2.3675e-03,  2.3292e-03,  3.0182e-03,  ...,  1.9820e-03,\n",
      "            1.9605e-03,  1.7935e-03],\n",
      "          [ 1.8981e-03,  2.9509e-03,  2.2337e-03,  ...,  2.2217e-03,\n",
      "            1.7044e-03,  1.9740e-03],\n",
      "          ...,\n",
      "          [ 2.9249e-03,  2.9074e-03,  3.8117e-03,  ...,  3.1212e-03,\n",
      "            3.0890e-03,  2.5676e-03],\n",
      "          [ 2.0956e-03,  2.9421e-03,  2.4861e-03,  ...,  3.1986e-03,\n",
      "            2.2032e-03,  2.6442e-03],\n",
      "          [ 2.3761e-03,  2.2773e-03,  3.0496e-03,  ...,  2.4990e-03,\n",
      "            2.5427e-03,  2.2065e-03]],\n",
      "\n",
      "         [[-2.3579e-04,  3.3187e-04, -6.8865e-06,  ..., -8.2796e-05,\n",
      "           -3.5474e-04, -2.1350e-04],\n",
      "          [ 3.2756e-04,  1.9062e-04,  7.9355e-04,  ..., -2.0164e-04,\n",
      "           -1.3898e-05, -3.1124e-04],\n",
      "          [-7.9541e-05,  7.1999e-04,  2.4548e-04,  ...,  1.0625e-04,\n",
      "           -2.5582e-04, -9.2242e-05],\n",
      "          ...,\n",
      "          [ 8.6318e-04,  5.4751e-04,  1.6974e-03,  ...,  4.4880e-04,\n",
      "            9.3468e-04,  1.4826e-04],\n",
      "          [-1.4789e-04,  7.2278e-04,  2.2359e-04,  ...,  7.6043e-04,\n",
      "            1.2887e-04,  2.8008e-04],\n",
      "          [ 3.6528e-04,  8.1250e-05,  9.5334e-04,  ...,  1.8940e-04,\n",
      "            4.8942e-04, -4.5317e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0427e-03,  1.3814e-03,  1.0860e-03,  ...,  1.8248e-03,\n",
      "            1.1036e-03,  1.3913e-03],\n",
      "          [ 1.3645e-03,  1.3768e-03,  1.6416e-03,  ...,  1.7673e-03,\n",
      "            1.8581e-03,  1.4419e-03],\n",
      "          [ 1.0882e-03,  1.6866e-03,  1.2332e-03,  ...,  2.4820e-03,\n",
      "            1.3738e-03,  1.8523e-03],\n",
      "          ...,\n",
      "          [ 1.7928e-03,  1.6828e-03,  2.3371e-03,  ...,  1.6263e-03,\n",
      "            1.5700e-03,  1.4124e-03],\n",
      "          [ 1.1872e-03,  1.8511e-03,  1.3246e-03,  ...,  1.6877e-03,\n",
      "            1.1501e-03,  1.4243e-03],\n",
      "          [ 1.4856e-03,  1.4312e-03,  1.8538e-03,  ...,  1.3933e-03,\n",
      "            1.3869e-03,  1.2369e-03]],\n",
      "\n",
      "         [[ 1.6269e-03,  2.2571e-03,  1.8241e-03,  ...,  3.1538e-03,\n",
      "            1.9670e-03,  2.4831e-03],\n",
      "          [ 2.2652e-03,  2.2289e-03,  2.7660e-03,  ...,  3.3398e-03,\n",
      "            3.1406e-03,  2.6598e-03],\n",
      "          [ 1.8383e-03,  2.6917e-03,  2.1068e-03,  ...,  4.2661e-03,\n",
      "            2.5505e-03,  3.2097e-03],\n",
      "          ...,\n",
      "          [ 2.8510e-03,  2.8359e-03,  3.6856e-03,  ...,  2.7250e-03,\n",
      "            2.7016e-03,  2.3098e-03],\n",
      "          [ 2.0643e-03,  2.8475e-03,  2.4203e-03,  ...,  2.7873e-03,\n",
      "            2.0144e-03,  2.3764e-03],\n",
      "          [ 2.3254e-03,  2.2288e-03,  2.9575e-03,  ...,  2.2643e-03,\n",
      "            2.2916e-03,  2.0393e-03]],\n",
      "\n",
      "         [[-2.7849e-04,  1.8996e-04, -5.6133e-05,  ...,  8.9453e-04,\n",
      "            6.1227e-05,  5.0850e-04],\n",
      "          [ 2.1330e-04,  8.8216e-05,  5.7386e-04,  ...,  6.8634e-04,\n",
      "            1.1265e-03,  1.9510e-04],\n",
      "          [-1.4228e-04,  5.3384e-04,  1.6349e-04,  ...,  1.7566e-03,\n",
      "            4.5334e-04,  9.1321e-04],\n",
      "          ...,\n",
      "          [ 7.9850e-04,  4.8473e-04,  1.5858e-03,  ...,  2.1930e-04,\n",
      "            6.1184e-04, -3.2862e-06],\n",
      "          [-1.7853e-04,  6.4924e-04,  1.9311e-04,  ...,  4.4573e-04,\n",
      "           -2.4269e-05,  9.4595e-05],\n",
      "          [ 3.2898e-04,  4.3441e-05,  8.7594e-04,  ...,  8.3931e-06,\n",
      "            2.7260e-04, -1.5885e-04]]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid adversarial|epoch4: 100%|██████████| 2/2 [00:01<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-4 average psnr:5.852162539958954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch5: 100%|██████████| 2/2 [00:01<00:00,  1.00it/s]\n",
      "valid adversarial|epoch5: 100%|██████████| 2/2 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-5 average psnr:5.854935348033905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch6: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n",
      "valid adversarial|epoch6: 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-6 average psnr:5.859017968177795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch7: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "valid adversarial|epoch7: 100%|██████████| 2/2 [00:01<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-7 average psnr:5.859347879886627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch8: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "valid adversarial|epoch8: 100%|██████████| 2/2 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-8 average psnr:5.924569666385651\n"
     ]
    }
   ],
   "source": [
    "srgan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(train_dataloader, epoch) -> None:\n",
    "\t\"\"\"Only train the generative model.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttrain_dataloader (torch.utils.data.DataLoader): The loader of the training data set.\n",
    "\t\tepoch (int): number of training cycles.\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Calculate how many iterations there are under Epoch.\n",
    "\tbatches = len(train_dataloader)\n",
    "\t# Put the generative model in training mode.\n",
    "\tgenerator.train()\n",
    "\n",
    "\tfor index, (lr, hr) in enumerate(train_dataloader):\n",
    "\t\t# Copy the data to the specified device.\n",
    "\t\tlr = lr.to(cfg.device)\n",
    "\t\thr = hr.to(cfg.device)\n",
    "\t\t# Initialize the gradient of the generated model.\n",
    "\t\tgenerator.zero_grad()\n",
    "\t\t# Generate super-resolution images.\n",
    "\t\tsr = generator(lr)\n",
    "\t\t# Calculate the difference between the super-resolution image and the high-resolution image at the pixel level.\n",
    "\t\tpixel_loss = pixel_criterion(sr, hr)\n",
    "\t\t# Update the weights of the generated model.\n",
    "\t\tpixel_loss.backward()\n",
    "\t\tp_optimizer.step()\n",
    "\t\t# Write the loss during training into Tensorboard.\n",
    "\t\titers = index + epoch * batches + 1\n",
    "\t\t# writer.add_scalar(\"Train/Loss\", pixel_loss.item(), iters)\n",
    "\t\t# # Print the loss function every ten iterations and the last iteration in this Epoch.\n",
    "\t\t# if (index + 1) % 10 == 0 or (index + 1) == batches:\n",
    "\t\t#     print(f\"Train Epoch[{epoch + 1:04d}/{p_epochs:04d}]({index + 1:05d}/{batches:05d}) \"\n",
    "\t\t#           f\"Loss: {pixel_loss.item():.6f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator=Discriminator().to(cfg.device)            # Load the discriminator model.\n",
    "generator=Generator().to(cfg.device)  \n",
    "p_optimizer=optim.Adam(generator.parameters(),     0.0001, (0.9, 0.999))  # Generate model learning rate during generator training.\n",
    "d_optimizer=optim.Adam(discriminator.parameters(), 0.0001, (0.9, 0.999))  # Discriminator learning rate during adversarial network training.\n",
    "g_optimizer=optim.Adam(generator.parameters(),     0.0001, (0.9, 0.999))  # The learning rate of the generator during network training.\n",
    "\n",
    "# Scheduler.\n",
    "d_scheduler=StepLR(d_optimizer, cfg.epochs // 2, 0.1)  # Identify the model scheduler during adversarial training.\n",
    "g_scheduler=StepLR(g_optimizer, cfg.epochs // 2, 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_criterion=nn.MSELoss().to(cfg.device)               # Pixel loss.\n",
    "content_criterion=ContentLoss(cfg).to(cfg.device)              # Content loss.\n",
    "adversarial_criterion=nn.BCELoss().to(cfg.device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CustomDataset(cfg,mode='train')\n",
    "valid_dataset=CustomDataset(cfg,mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,cfg.batch_size,True,pin_memory=True)\n",
    "valid_loader=DataLoader(valid_dataset,cfg.batch_size,True,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator(train_loader,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_adversarial(train_dataloader, epoch) -> None:\n",
    "\t\"\"\"Training generative models and adversarial models.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttrain_dataloader (torch.utils.data.DataLoader): The loader of the training data set.\n",
    "\t\tepoch (int): number of training cycles.\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Calculate how many iterations there are under Epoch.\n",
    "\tbatches = len(train_dataloader)\n",
    "\t# Put the two models in training mode.\n",
    "\tdiscriminator.train()\n",
    "\tgenerator.train()\n",
    "\n",
    "\tfor index, (lr, hr) in enumerate(train_dataloader):\n",
    "\t\t# Copy the data to the specified device.\n",
    "\t\tlr = lr.to(cfg.device)\n",
    "\t\thr = hr.to(cfg.device)\n",
    "\t\tlabel_size = lr.size(0)\n",
    "\t\t# 打label. Set the real sample label to 1, and the false sample label to 0.\n",
    "\t\treal_label = torch.full([label_size, 1], 1.0, dtype=lr.dtype, device=cfg.device)\n",
    "\t\tfake_label = torch.full([label_size, 1], 0.0, dtype=lr.dtype, device=cfg.device)\n",
    "\n",
    "\t\t# Initialize the identification model gradient.\n",
    "\t\tdiscriminator.zero_grad()\n",
    "\t\t# Generate super-resolution images.\n",
    "\t\tsr = generator(lr)\n",
    "\t\t# Calculate the loss of the identification model on the high-resolution image.\n",
    "\t\thr_output = discriminator(hr)\n",
    "\n",
    "\t\tsr_output = discriminator(sr.detach())\n",
    "\t\tdiff=hr_output - torch.mean(sr_output)\n",
    "\t\tdiff[diff<0]=0\n",
    "\t\td_loss_hr = adversarial_criterion(diff, real_label)\n",
    "\t\td_loss_hr.backward()\n",
    "\t\td_hr = hr_output.mean().item()\n",
    "\t\t# Calculate the loss of the identification model on the super-resolution image.\n",
    "\t\thr_output = discriminator(hr)\n",
    "\n",
    "\t\tsr_output = discriminator(sr.detach())\n",
    "\t\tdiff=sr_output - torch.mean(hr_output)\n",
    "\t\tdiff[diff<0]=0\n",
    "\t\td_loss_sr = adversarial_criterion(diff, fake_label)\n",
    "\t\td_loss_sr.backward()\n",
    "\t\td_sr1 = sr_output.mean().item()\n",
    "\t\t# Update the weights of the authentication model.\n",
    "\t\td_loss = d_loss_hr + d_loss_sr\n",
    "\t\td_optimizer.step()\n",
    "\n",
    "\t\t# Initialize the gradient of the generated model.\n",
    "\t\tgenerator.zero_grad()\n",
    "\t\t# Generate super-resolution images.\n",
    "\t\tsr = generator(lr)\n",
    "\t\t# Calculate the loss of the identification model on the super-resolution image.\n",
    "\t\thr_output = discriminator(hr.detach())\n",
    "\t\tsr_output = discriminator(sr)\n",
    "\t\t# Perceptual loss = 0.01 * pixel loss + 1.0 * content loss + 0.005 * counter loss.\n",
    "\t\tpixel_loss = cfg.pixel_weight * pixel_criterion(sr, hr.detach())\n",
    "\t\tcontent_loss = cfg.content_weight * content_criterion(sr, hr.detach())\n",
    "\t\tdiff=sr_output - torch.mean(hr_output)\n",
    "\t\tdiff[diff<0]=0\n",
    "\t\tadversarial_loss = cfg.adversarial_weight * adversarial_criterion(diff, real_label)\n",
    "\t\t# Update the weights of the generated model.\n",
    "\t\tg_loss = pixel_loss + content_loss + adversarial_loss\n",
    "\t\tg_loss.backward()\n",
    "\t\tg_optimizer.step()\n",
    "\t\t# d_sr2 = sr_output.mean().item()\n",
    "\n",
    "\t\t# # Write the loss during training into Tensorboard.\n",
    "\t\t# iters = index + epoch * batches + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adversarial(train_loader,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_dataloader, epoch, stage) -> float:\n",
    "    \"\"\"Verify the generative model.\n",
    "\n",
    "    Args:\n",
    "        valid_dataloader (torch.utils.data.DataLoader): loader for validating data set.\n",
    "        epoch (int): number of training cycles.\n",
    "        stage (str): In which stage to verify, one is `generator`, the other is `adversarial`.\n",
    "\n",
    "    Returns:\n",
    "        PSNR value(float).\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate how many iterations there are under Epoch.\n",
    "    batches = len(valid_dataloader)\n",
    "    # Put the generated model in verification mode.\n",
    "    generator.eval()\n",
    "    # Initialize the evaluation index.\n",
    "    total_psnr_value = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (lr, hr) in enumerate(valid_dataloader):\n",
    "            # Copy the data to the specified device.\n",
    "            lr = lr.to(cfg.device)\n",
    "            hr = hr.to(cfg.device)\n",
    "            # Generate super-resolution images.\n",
    "            sr = generator(lr)\n",
    "            # Calculate the PSNR indicator.\n",
    "            mse_loss = ((sr - hr) ** 2).data.mean()\n",
    "            psnr_value = 10 * torch.log10(1 / mse_loss).item()\n",
    "            total_psnr_value += psnr_value\n",
    "\n",
    "        avg_psnr_value = total_psnr_value / batches\n",
    "        # Write the value of each round of verification indicators into Tensorboard.\n",
    "        # Print evaluation indicators.\n",
    "        print(f\"Valid stage: {stage} Epoch[{epoch + 1:04d}] avg PSNR: {avg_psnr_value:.2f}.\\n\")\n",
    "\n",
    "    return avg_psnr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid stage: generator Epoch[0001] avg PSNR: 5.85.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.848747342824936"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(valid_loader,0,'generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
