{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode as IMode\n",
    "from torch.utils.data import DataLoader\n",
    "from narutils import *\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from utils.imgproc import *\n",
    "from model import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうやらSRGANは最初のp_epochsはgeneratorだけを学習，advはepochsだけらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file paths\n",
    "data_dir='/work/dataset/images1024x1024/'\n",
    "fpaths=[]\n",
    "for d in os.listdir(data_dir):\n",
    "\tfpaths+=glob(opj(data_dir,d,'*.png'))\n",
    "path_df=dfc(fpaths).rename(columns={0:'file_path'}).to_csv('path_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "\tdevice = torch.device(\"cuda:0\")\n",
    "\tseed=19\n",
    "\tupscale_factor=4\n",
    "\timage_size=512 # hr image size(low res image size=image_size/upscale_factor)\n",
    "\tbatch_size=4\n",
    "\n",
    "\t# Train epochs.\n",
    "\tp_epochs=50 # The total number of cycles of the generator training phase.\n",
    "\tepochs=10  # The total number of cycles in the training phase of the adversarial network.\n",
    "\n",
    "\tmodel_dir='./exp-debug'\n",
    "\n",
    "\texp_name='test'\n",
    "\tvgg_path='/work/dataset/vgg-pre.pickle'\n",
    "\ttrain_path_df=pd.read_csv('path_df.csv').iloc[:5000,:]\n",
    "\tvalid_path_df=pd.read_csv('path_df.csv').iloc[5000:10000,:]\n",
    "\n",
    "\tpixel_weight          = 0.01\n",
    "\tcontent_weight        = 1.0\n",
    "\tadversarial_weight    = 0.001\n",
    "\n",
    "\tdebug=True\n",
    "\n",
    "\n",
    "\tif debug:\n",
    "\t\ttrain_path_df=train_path_df.iloc[:8,:]\n",
    "\t\tvalid_path_df=valid_path_df.iloc[:8,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self,cfg,mode='train'):\n",
    "\t\tlr_image_size=(cfg.image_size//cfg.upscale_factor,cfg.image_size//cfg.upscale_factor)\n",
    "\t\thr_image_size=(cfg.image_size,cfg.image_size)\n",
    "\t\tself.hr_transforms=transforms.Compose([\n",
    "\t\t\ttransforms.Resize(hr_image_size,interpolation=IMode.BICUBIC),\n",
    "\t\t])\n",
    "\t\tself.lr_transforms=transforms.Compose([\n",
    "\t\t\ttransforms.Resize(lr_image_size,interpolation=IMode.BICUBIC),\n",
    "\t\t])\n",
    "\t\tif mode=='train':\n",
    "\t\t\tself.filenames=cfg.train_path_df['file_path'].values\n",
    "\t\telif mode=='valid':\n",
    "\t\t\tself.filenames=cfg.valid_path_df['file_path'].values\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError\n",
    "\n",
    "\tdef __getitem__(self,index):\n",
    "\t\thr=image2tensor(cv2.imread(self.filenames[index],-1))\n",
    "\t\tlr=self.lr_transforms(hr)\n",
    "\t\thr=self.hr_transforms(hr)\n",
    "\t\treturn lr,hr\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN():\n",
    "\tdef __init__(self,cfg):\n",
    "\t\tself.cfg=cfg\n",
    "\n",
    "\tdef build_dataloader(self,CustomDataset):\n",
    "\t\tself.train_dataset=CustomDataset(self.cfg,mode='train')\n",
    "\t\tself.valid_dataset=CustomDataset(self.cfg,mode='valid')\n",
    "\n",
    "\t\tself.train_loader=DataLoader(self.train_dataset,self.cfg.batch_size,True,pin_memory=True)\n",
    "\t\tself.valid_loader=DataLoader(self.valid_dataset,self.cfg.batch_size,True,pin_memory=True)\n",
    "\n",
    "\t\tdecopri('successfully built data loaders!')\n",
    "\n",
    "\tdef build_model(self):\n",
    "\t\tself.discriminator=Discriminator().to(self.cfg.device)\n",
    "\t\tself.generator=Generator().to(self.cfg.device)\n",
    "\n",
    "\t\tdecopri('successfully built models!')\n",
    "\n",
    "\tdef train_generator(self,epoch):\n",
    "\t\t\"\"\"Only train the generative model.\n",
    "\t\tArgs:\n",
    "\t\t\ttrain_dataloader (torch.utils.data.DataLoader): The loader of the training data set.\n",
    "\t\t\tepoch (int): number of training cycles.\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t# Calculate how many iterations there are under Epoch.\n",
    "\t\tbatches = len(self.train_loader)\n",
    "\t\t# Put the generative model in training mode.\n",
    "\t\tself.generator.train()\n",
    "\t\tpbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader), desc=f'Train generator|epoch{epoch}',dynamic_ncols=True)\n",
    "\t\tfor index, (lr, hr) in pbar:\n",
    "\t\t\t# Copy the data to the specified device.\n",
    "\t\t\tlr = lr.to(cfg.device)\n",
    "\t\t\thr = hr.to(cfg.device)\n",
    "\t\t\t# Initialize the gradient of the generated model.\n",
    "\t\t\tself.generator.zero_grad()\n",
    "\t\t\t# Generate super-resolution images.\n",
    "\t\t\tsr = self.generator(lr)\n",
    "\t\t\t# Calculate the difference between the super-resolution image and the high-resolution image at the pixel level.\n",
    "\t\t\tpixel_loss = self.pixel_criterion(sr, hr)\n",
    "\t\t\t# Update the weights of the generated model.\n",
    "\t\t\tpixel_loss.backward()\n",
    "\t\t\tself.p_optimizer.step()\n",
    "\t\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tself.p_optimizer=optim.Adam(self.generator.parameters(),0.0001,(0.9, 0.999))  # Generate model learning rate during generator training.\n",
    "\t\tself.d_optimizer=optim.Adam(self.discriminator.parameters(),0.0001,(0.9, 0.999))  # Discriminator learning rate during adversarial network training.\n",
    "\t\tself.g_optimizer=optim.Adam(self.generator.parameters(),0.0001,(0.9, 0.999))  # The learning rate of the generator during network training.\n",
    "\n",
    "\t\t# Scheduler.\n",
    "\t\tself.d_scheduler=StepLR(self.d_optimizer, self.cfg.epochs // 2, 0.1)  # Identify the model scheduler during adversarial training.\n",
    "\t\tself.g_scheduler=StepLR(self.g_optimizer, self.cfg.epochs // 2, 0.1)\n",
    "\t\t\n",
    "\t\t# Loss functions\n",
    "\t\tself.pixel_criterion=nn.MSELoss().to(cfg.device)               # Pixel loss.\n",
    "\t\tself.content_criterion=ContentLoss(cfg).to(cfg.device)              # Content loss.\n",
    "\t\tself.adversarial_criterion=nn.BCELoss().to(cfg.device) \n",
    "\n",
    "\t\t# train only generator stage\n",
    "\t\tdecopri('Start train generator stage')\n",
    "\t\tpsnr_best=0.0\n",
    "\t\tfor epoch in range(self.cfg.p_epochs):\n",
    "\t\t\tself.train_generator(epoch)\n",
    "\t\t\tpsnr=self.validate(epoch,stage='generator only')\n",
    "\t\t\tif (epoch+1)%5==0:\n",
    "\t\t\t\ttorch.save(self.generator.state_dict(),opj(self.cfg.model_dir,f'p-{epoch}.pth'))\n",
    "\t\t\tif psnr>psnr_best:\n",
    "\t\t\t\tpsnr_best=psnr\n",
    "\t\t\t\tmkdirs(self.cfg.model_dir)\n",
    "\t\t\t\ttorch.save(self.generator.state_dict(),opj(self.cfg.model_dir,'p-best.pth'))\n",
    "\t\t\n",
    "\t\t# train adversarial stage\n",
    "\t\tself.generator.load_state_dict(torch.load(opj(cfg.model_dir,'p-best.pth')))\n",
    "\n",
    "\n",
    "\tdef validate(self,epoch,stage='adversarial'):\n",
    "\t\tbatches=len(self.valid_loader)\n",
    "\t\tself.generator.eval()\n",
    "\t\ttotal_psnr_value=0.0\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tpbar=tqdm(enumerate(self.valid_loader), total=len(self.valid_loader), desc=f'valid {stage}|epoch{epoch}',dynamic_ncols=True)\n",
    "\t\t\tfor index,(lr,hr) in pbar:\n",
    "\t\t\t\tlr = lr.to(self.cfg.device)\n",
    "\t\t\t\thr = hr.to(self.cfg.device)\n",
    "\t\t\t\t# Generate super-resolution images.\n",
    "\t\t\t\tsr = self.generator(lr)\n",
    "\t\t\t\t# Calculate the PSNR indicator.\n",
    "\t\t\t\tmse_loss = ((sr - hr) ** 2).data.mean()\n",
    "\t\t\t\tpsnr_value = 10 * torch.log10(1 / mse_loss).item()\n",
    "\t\t\t\ttotal_psnr_value += psnr_value\n",
    "\t\t\t\n",
    "\t\t\tavg_psnr_value=total_psnr_value/batches\n",
    "\t\t\tprint(f'epoch-{epoch} average psnr:{avg_psnr_value}')\n",
    "\n",
    "\t\treturn avg_psnr_value\n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan=SRGAN(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "                        successfully built data loaders!                        \n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "                           successfully built models!                           \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "srgan.build_dataloader(CustomDataset=CustomDataset)\n",
    "srgan.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "                          Start train generator stage                          \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch0: 100%|██████████| 2/2 [00:00<00:00,  3.64it/s]\n",
      "valid generator only|epoch0: 100%|██████████| 2/2 [00:00<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0 average psnr:5.834514796733856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch1: 100%|██████████| 2/2 [00:00<00:00,  2.49it/s]\n",
      "valid generator only|epoch1: 100%|██████████| 2/2 [00:00<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-1 average psnr:5.868099629878998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch2: 100%|██████████| 2/2 [00:00<00:00,  3.78it/s]\n",
      "valid generator only|epoch2: 100%|██████████| 2/2 [00:00<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-2 average psnr:6.0206955671310425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch3: 100%|██████████| 2/2 [00:00<00:00,  2.32it/s]\n",
      "valid generator only|epoch3: 100%|██████████| 2/2 [00:00<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-3 average psnr:6.227478086948395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch4: 100%|██████████| 2/2 [00:00<00:00,  4.10it/s]\n",
      "valid generator only|epoch4: 100%|██████████| 2/2 [00:00<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-4 average psnr:6.669838130474091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train generator|epoch5:  50%|█████     | 1/2 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mセル9 を /work/sr-security-camera/script/srgan_naru/dev.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=0'>1</a>\u001b[0m srgan\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[1;32mセル9 を /work/sr-security-camera/script/srgan_naru/dev.ipynb\u001b[0m in \u001b[0;36mSRGAN.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=62'>63</a>\u001b[0m psnr_best\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mp_epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=64'>65</a>\u001b[0m \t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_generator(epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=65'>66</a>\u001b[0m \tpsnr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate(epoch,stage\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgenerator only\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=66'>67</a>\u001b[0m \t\u001b[39mif\u001b[39;00m (epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m%\u001b[39m\u001b[39m5\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n",
      "\u001b[1;32mセル9 を /work/sr-security-camera/script/srgan_naru/dev.ipynb\u001b[0m in \u001b[0;36mSRGAN.train_generator\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=29'>30</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=30'>31</a>\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader), desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain generator|epoch\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,dynamic_ncols\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, (lr, hr) \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=32'>33</a>\u001b[0m \t\u001b[39m# Copy the data to the specified device.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=33'>34</a>\u001b[0m \tlr \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mto(cfg\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=34'>35</a>\u001b[0m \thr \u001b[39m=\u001b[39m hr\u001b[39m.\u001b[39mto(cfg\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mセル9 を /work/sr-security-camera/script/srgan_naru/dev.ipynb\u001b[0m in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m,index):\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=18'>19</a>\u001b[0m \thr\u001b[39m=\u001b[39mimage2tensor(cv2\u001b[39m.\u001b[39;49mimread(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilenames[index],\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=19'>20</a>\u001b[0m \tlr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_transforms(hr)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f637564613131342d7562756e7475323030342d6e6172756d6f746f222c2273657474696e6773223a7b22686f7374223a227373683a2f2f76696c6c696572227d7d/work/sr-security-camera/script/srgan_naru/dev.ipynb#ch0000038vscode-remote?line=20'>21</a>\u001b[0m \thr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhr_transforms(hr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "srgan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(train_dataloader, epoch) -> None:\n",
    "\t\"\"\"Only train the generative model.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttrain_dataloader (torch.utils.data.DataLoader): The loader of the training data set.\n",
    "\t\tepoch (int): number of training cycles.\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Calculate how many iterations there are under Epoch.\n",
    "\tbatches = len(train_dataloader)\n",
    "\t# Put the generative model in training mode.\n",
    "\tgenerator.train()\n",
    "\n",
    "\tfor index, (lr, hr) in enumerate(train_dataloader):\n",
    "\t\t# Copy the data to the specified device.\n",
    "\t\tlr = lr.to(cfg.device)\n",
    "\t\thr = hr.to(cfg.device)\n",
    "\t\t# Initialize the gradient of the generated model.\n",
    "\t\tgenerator.zero_grad()\n",
    "\t\t# Generate super-resolution images.\n",
    "\t\tsr = generator(lr)\n",
    "\t\t# Calculate the difference between the super-resolution image and the high-resolution image at the pixel level.\n",
    "\t\tpixel_loss = pixel_criterion(sr, hr)\n",
    "\t\t# Update the weights of the generated model.\n",
    "\t\tpixel_loss.backward()\n",
    "\t\tp_optimizer.step()\n",
    "\t\t# Write the loss during training into Tensorboard.\n",
    "\t\titers = index + epoch * batches + 1\n",
    "\t\t# writer.add_scalar(\"Train/Loss\", pixel_loss.item(), iters)\n",
    "\t\t# # Print the loss function every ten iterations and the last iteration in this Epoch.\n",
    "\t\t# if (index + 1) % 10 == 0 or (index + 1) == batches:\n",
    "\t\t#     print(f\"Train Epoch[{epoch + 1:04d}/{p_epochs:04d}]({index + 1:05d}/{batches:05d}) \"\n",
    "\t\t#           f\"Loss: {pixel_loss.item():.6f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator=Discriminator().to(cfg.device)            # Load the discriminator model.\n",
    "generator=Generator().to(cfg.device)  \n",
    "p_optimizer=optim.Adam(generator.parameters(),     0.0001, (0.9, 0.999))  # Generate model learning rate during generator training.\n",
    "d_optimizer=optim.Adam(discriminator.parameters(), 0.0001, (0.9, 0.999))  # Discriminator learning rate during adversarial network training.\n",
    "g_optimizer=optim.Adam(generator.parameters(),     0.0001, (0.9, 0.999))  # The learning rate of the generator during network training.\n",
    "\n",
    "# Scheduler.\n",
    "d_scheduler=StepLR(d_optimizer, cfg.epochs // 2, 0.1)  # Identify the model scheduler during adversarial training.\n",
    "g_scheduler=StepLR(g_optimizer, cfg.epochs // 2, 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_criterion=nn.MSELoss().to(cfg.device)               # Pixel loss.\n",
    "content_criterion=ContentLoss(cfg).to(cfg.device)              # Content loss.\n",
    "adversarial_criterion=nn.BCELoss().to(cfg.device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CustomDataset(cfg,mode='train')\n",
    "valid_dataset=CustomDataset(cfg,mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,cfg.batch_size,True,pin_memory=True)\n",
    "valid_loader=DataLoader(valid_dataset,cfg.batch_size,True,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator(train_loader,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_adversarial(train_dataloader, epoch) -> None:\n",
    "\t\"\"\"Training generative models and adversarial models.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttrain_dataloader (torch.utils.data.DataLoader): The loader of the training data set.\n",
    "\t\tepoch (int): number of training cycles.\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Calculate how many iterations there are under Epoch.\n",
    "\tbatches = len(train_dataloader)\n",
    "\t# Put the two models in training mode.\n",
    "\tdiscriminator.train()\n",
    "\tgenerator.train()\n",
    "\n",
    "\tfor index, (lr, hr) in enumerate(train_dataloader):\n",
    "\t\t# Copy the data to the specified device.\n",
    "\t\tlr = lr.to(cfg.device)\n",
    "\t\thr = hr.to(cfg.device)\n",
    "\t\tlabel_size = lr.size(0)\n",
    "\t\t# 打label. Set the real sample label to 1, and the false sample label to 0.\n",
    "\t\treal_label = torch.full([label_size, 1], 1.0, dtype=lr.dtype, device=cfg.device)\n",
    "\t\tfake_label = torch.full([label_size, 1], 0.0, dtype=lr.dtype, device=cfg.device)\n",
    "\n",
    "\t\t# Initialize the identification model gradient.\n",
    "\t\tdiscriminator.zero_grad()\n",
    "\t\t# Generate super-resolution images.\n",
    "\t\tsr = generator(lr)\n",
    "\t\t# Calculate the loss of the identification model on the high-resolution image.\n",
    "\t\thr_output = discriminator(hr)\n",
    "\n",
    "\t\tsr_output = discriminator(sr.detach())\n",
    "\t\tdiff=hr_output - torch.mean(sr_output)\n",
    "\t\tdiff[diff<0]=0\n",
    "\t\td_loss_hr = adversarial_criterion(diff, real_label)\n",
    "\t\td_loss_hr.backward()\n",
    "\t\td_hr = hr_output.mean().item()\n",
    "\t\t# Calculate the loss of the identification model on the super-resolution image.\n",
    "\t\thr_output = discriminator(hr)\n",
    "\n",
    "\t\tsr_output = discriminator(sr.detach())\n",
    "\t\tdiff=sr_output - torch.mean(hr_output)\n",
    "\t\tdiff[diff<0]=0\n",
    "\t\td_loss_sr = adversarial_criterion(diff, fake_label)\n",
    "\t\td_loss_sr.backward()\n",
    "\t\td_sr1 = sr_output.mean().item()\n",
    "\t\t# Update the weights of the authentication model.\n",
    "\t\td_loss = d_loss_hr + d_loss_sr\n",
    "\t\td_optimizer.step()\n",
    "\n",
    "\t\t# Initialize the gradient of the generated model.\n",
    "\t\tgenerator.zero_grad()\n",
    "\t\t# Generate super-resolution images.\n",
    "\t\tsr = generator(lr)\n",
    "\t\t# Calculate the loss of the identification model on the super-resolution image.\n",
    "\t\thr_output = discriminator(hr.detach())\n",
    "\t\tsr_output = discriminator(sr)\n",
    "\t\t# Perceptual loss = 0.01 * pixel loss + 1.0 * content loss + 0.005 * counter loss.\n",
    "\t\tpixel_loss = cfg.pixel_weight * pixel_criterion(sr, hr.detach())\n",
    "\t\tcontent_loss = cfg.content_weight * content_criterion(sr, hr.detach())\n",
    "\t\tdiff=sr_output - torch.mean(hr_output)\n",
    "\t\tdiff[diff<0]=0\n",
    "\t\tadversarial_loss = cfg.adversarial_weight * adversarial_criterion(diff, real_label)\n",
    "\t\t# Update the weights of the generated model.\n",
    "\t\tg_loss = pixel_loss + content_loss + adversarial_loss\n",
    "\t\tg_loss.backward()\n",
    "\t\tg_optimizer.step()\n",
    "\t\t# d_sr2 = sr_output.mean().item()\n",
    "\n",
    "\t\t# # Write the loss during training into Tensorboard.\n",
    "\t\t# iters = index + epoch * batches + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adversarial(train_loader,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_dataloader, epoch, stage) -> float:\n",
    "    \"\"\"Verify the generative model.\n",
    "\n",
    "    Args:\n",
    "        valid_dataloader (torch.utils.data.DataLoader): loader for validating data set.\n",
    "        epoch (int): number of training cycles.\n",
    "        stage (str): In which stage to verify, one is `generator`, the other is `adversarial`.\n",
    "\n",
    "    Returns:\n",
    "        PSNR value(float).\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate how many iterations there are under Epoch.\n",
    "    batches = len(valid_dataloader)\n",
    "    # Put the generated model in verification mode.\n",
    "    generator.eval()\n",
    "    # Initialize the evaluation index.\n",
    "    total_psnr_value = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (lr, hr) in enumerate(valid_dataloader):\n",
    "            # Copy the data to the specified device.\n",
    "            lr = lr.to(cfg.device)\n",
    "            hr = hr.to(cfg.device)\n",
    "            # Generate super-resolution images.\n",
    "            sr = generator(lr)\n",
    "            # Calculate the PSNR indicator.\n",
    "            mse_loss = ((sr - hr) ** 2).data.mean()\n",
    "            psnr_value = 10 * torch.log10(1 / mse_loss).item()\n",
    "            total_psnr_value += psnr_value\n",
    "\n",
    "        avg_psnr_value = total_psnr_value / batches\n",
    "        # Write the value of each round of verification indicators into Tensorboard.\n",
    "        # Print evaluation indicators.\n",
    "        print(f\"Valid stage: {stage} Epoch[{epoch + 1:04d}] avg PSNR: {avg_psnr_value:.2f}.\\n\")\n",
    "\n",
    "    return avg_psnr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid stage: generator Epoch[0001] avg PSNR: 5.85.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.848747342824936"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(valid_loader,0,'generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
